{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f8c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib\n",
    "from matplotlib import rc\n",
    "rc('axes', linewidth=1.2)\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f1406",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setting up the parameters of the RFMEONP\n",
    "\"\"\"\n",
    "sites = np.array([10,7])\n",
    "lamda1 = [1 for i in range(11)]\n",
    "lamda2= [1 for i in range(8)]\n",
    "lamda = [lamda1, lamda2]\n",
    "p = sum(sites)+1\n",
    "l = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf32712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generating the Training and Test Sets\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Training Set Generation\n",
    "\"\"\"\n",
    "h = 0.1\n",
    "h1 = 0.1\n",
    "t = np.arange(0, 1+h, h)\n",
    "H = np.array(np.arange(0.1, 1+h1, h1).tolist())\n",
    "Tr = []\n",
    "for j in range(len(H)):\n",
    "    for i in range(len(t)):\n",
    "        Tr.append([t[i],H[j]])\n",
    "scale = 10000\n",
    "Tr = np.array(Tr).T\n",
    "ntrain = Tr.shape[1]\n",
    "\"\"\"\n",
    "Testing Set Generation\n",
    "\"\"\"\n",
    "h = 0.0001\n",
    "h1 = 0.005\n",
    "t0 = np.arange(0, 1+h1, h1)\n",
    "H0 = np.arange(0.1, 1.005, 0.005)\n",
    "# H0 = np.arange(0.1, 1+h1, h1)\n",
    "Te = []\n",
    "for j in range(len(H0)):\n",
    "    for i in range(len(t0)):\n",
    "        Te.append([t0[i],H0[j]])\n",
    "scale = 10000\n",
    "Te = np.array(Te).T\n",
    "ntest = Te.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2e78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def G(Z):\n",
    "    return Z\n",
    "\n",
    "def Gprime(Z):\n",
    "    return 1.0\n",
    "\n",
    "def funct(y, lamda, sites, l, H, l5):\n",
    "    f = y.copy()\n",
    "    n = sum(sites)\n",
    "    lamda[0][4] = l5\n",
    "    Y = 2*H*y[n]\n",
    "    for i in range(len(sites)):\n",
    "        k = sum(sites[:i])\n",
    "        p = sites[i]\n",
    "        ii = 0\n",
    "        z1 = 0\n",
    "        z2 = 0\n",
    "        for j in range(k, k+l):\n",
    "            z1 += y[j]\n",
    "            z2 += y[j+1]\n",
    "        f[k] = lamda[i][ii]*G(Y)*(1-z1)-lamda[i][ii+1]*y[k]*(1-z2)\n",
    "        \n",
    "        ii += 1\n",
    "        \n",
    "        for tt in range(k+1, k+p-l):\n",
    "            z1 = 0\n",
    "            z2 = 0\n",
    "            for j in range(tt, tt+l):\n",
    "                z1 += y[j]\n",
    "                z2 += y[j+1]\n",
    "            f[tt] = lamda[i][ii]*y[tt-1]*(1-z1)-lamda[i][ii+1]*y[tt]*(1-z2)#verify\n",
    "            ii += 1\n",
    "#         print(z2)\n",
    "        f[k+p-l] = lamda[i][ii]*y[tt]*(1-z2)-lamda[i][ii+1]*y[k+p-l]\n",
    "        ii += 1\n",
    "        \n",
    "        for kk in range(k+p-l+1, k+p):\n",
    "            f[kk] = lamda[i][ii]*y[kk-1]-lamda[i][ii+1]*y[kk]\n",
    "            ii += 1\n",
    "        \n",
    "#         sitesn += lamda[i][ii]*y[k+p-1]\n",
    "    sites0 = 0\n",
    "    sitesn = 0\n",
    "    for i in range(len(sites)):\n",
    "        k = sum(sites[:i])\n",
    "        p = sites[i]\n",
    "        z1 = 0\n",
    "        for j in range(k,k+l):\n",
    "            z1 += y[j]\n",
    "        sites0 += lamda[i][0]*G(Y)*(1-z1)\n",
    "        sitesn += lamda[i][p]*y[k+p-1]\n",
    "    f[n] = 1/(2*H)*(sitesn-sites0)\n",
    "    return scale*f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf18251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights_biases(initialiser, N0, N1):\n",
    "    if initialiser.upper() == 'NORMAL':\n",
    "        return [np.random.normal(0,np.sqrt(2/N1),(N1,N0)), np.random.normal(0, np.sqrt(2/N1), (N1,1))]\n",
    "    if initialiser.upper() == 'UNIFORM':\n",
    "        return [np.random.uniform(0,np.sqrt(2/N1),(N1,N0)),np.random.uniform(0,0.05,(N1,1))]\n",
    "    if initialiser.upper() == 'XAVIER':\n",
    "        return [np.random.uniform(0, 1/np.sqrt(N1), (N1,N0)), np.random.normal(0, 1/np.sqrt(N1), (N1,1))]\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def add_layer(input_shape, hidden_units , activation = 'sigmoid', initialiser = 'normal'): \n",
    "    weights_biases = init_weights_biases(initialiser, input_shape, hidden_units)\n",
    "    NA.append(activation)\n",
    "    NW.append(weights_biases[0])\n",
    "    NB.append(weights_biases[1])\n",
    "    return None\n",
    "\n",
    "def estimated_derivative(A, Z, NA, NW, NB, t):\n",
    "    dydt = 1\n",
    "    return 1\n",
    "\n",
    "def activation_function(x, string, alpha = 0.01):\n",
    "    if string.upper() == 'SIGMOID':\n",
    "        return (1/(1+np.exp(-x)))\n",
    "    if string.upper() == 'ISIGMOID':\n",
    "        return -(1/(1+np.exp(-x)))\n",
    "    if string.upper() == 'BPS':\n",
    "        return  2*(1/(1+np.exp(-x)))-1\n",
    "    if string.upper() == 'IBPS':\n",
    "        return  1-2*(1/(1+np.exp(-x)))\n",
    "    if string.upper() == 'TRIG' or string.upper() == 'TRIGNOMETRIC':\n",
    "        return np.cos(x)\n",
    "    if string.upper() == 'CUSTOM':\n",
    "        return 0.9*np.tanh(x)-0.5*(1/(1+np.exp(-x)))\n",
    "    if string.upper() == 'TANH':\n",
    "        return np.tanh(x)\n",
    "    if string.upper() == 'RELU':\n",
    "        return (x+np.abs(x))/2\n",
    "    if string.upper() == 'LEAKYRELU' or string.upper() == 'LR':\n",
    "        return (x+alpha*x+np.abs(x-alpha*x))/2\n",
    "    if string.upper() == 'LINEAR':\n",
    "        return x\n",
    "    if string.upper() == 'EXPONENTIAL' or string.upper() == 'EXP':\n",
    "        return np.exp(x)\n",
    "    if string.upper() == 'ELU':\n",
    "        x[x<0] = 0.01*(np.exp(x[x<0])-1)\n",
    "        return x\n",
    "    if string.upper() == 'EXP':\n",
    "        return np.exp(-x)\n",
    "    return None\n",
    "    \n",
    "def activation_derivative(x, string, alpha = 0.01):\n",
    "    if string.upper() == 'SIGMOID':\n",
    "        return (1/(1+np.exp(-x)))*(1-(1/(1+np.exp(-x))))\n",
    "    if string.upper() == 'ISIGMOID':\n",
    "        return -(1/(1+np.exp(-x)))*(1-(1/(1+np.exp(-x))))\n",
    "    if string.upper() == 'BPS':\n",
    "        return 2*(1/(1+np.exp(-x)))*(1-(1/(1+np.exp(-x))))\n",
    "    if string.upper() == 'IBPS':\n",
    "        return -2*(1/(1+np.exp(-x)))*(1-(1/(1+np.exp(-x))))\n",
    "    if string.upper() == 'TRIG' or string.upper() == 'TRIGNOMETRIC':\n",
    "        return -np.sin(x)\n",
    "    if string.upper() == 'TANH':\n",
    "        return (1-np.tanh(x)**2)\n",
    "    if string.upper() == \"RELU\":\n",
    "        x[x<0] = 0\n",
    "        x[x>=0] = 1\n",
    "        return x\n",
    "    if string.upper() == 'CUSTOM':\n",
    "        return 0.9*(1-np.tanh(2*x)**2)-0.5*(1/(1+np.exp(-x)))*(1-(1/(1+np.exp(-x))))\n",
    "    if string.upper() == 'LEAKYRELU' or string.upper() == 'LR':\n",
    "        dx = np.ones(x.shape)\n",
    "        dx[x < 0] = alpha\n",
    "        x = dx.copy()\n",
    "        return x\n",
    "    if string.upper() == 'LINEAR':\n",
    "        x = 1\n",
    "        return x\n",
    "    if string.upper() == 'EXPONENTIAL' or string.upper() == 'EXP':\n",
    "        return np.exp(x)\n",
    "    if string.upper() == 'ELU':\n",
    "        x[x>=0] = 1\n",
    "        x[x<0] = 0.01*(np.exp(x[x<0]))\n",
    "        return x\n",
    "    if string.upper() == 'EXP':\n",
    "        return -np.exp(-x)\n",
    "    return None\n",
    "    \n",
    "def forward_propagation(X,NA,NW,NB):\n",
    "    A = [X]\n",
    "    Z = []\n",
    "    for i in range(len(NA)):\n",
    "        Zstar = (NW[i]@A[i]+NB[i])\n",
    "        Astar = activation_function(Zstar.astype(float), NA[i])\n",
    "        Z.append(Zstar.astype(float))\n",
    "        A.append(Astar)\n",
    "    return([Z,A])\n",
    "\n",
    "def backward_propagation(NA, NW, Z, A, dZ, dW, dB, T, y_hat, f, sites, l, lamda, H, alpha):\n",
    "    Adot = (np.gradient(A[L], 0.1)[0]/scale)-10**-10\n",
    "    Adotdot = (np.gradient(Adot, 0.1)[0]/scale)\n",
    "    dAL = [0 for i in range(sum(sites)+1)]\n",
    "    y = y_hat.copy()\n",
    "    lamda[0][4] = T[1]#Free parameter replaced with list of second feature variable\n",
    "    n = sum(sites)\n",
    "    sites0 = 0\n",
    "    t = T[0]\n",
    "    total = y[n]\n",
    "    penalty = alpha#penalty parameter for the COP loss\n",
    "    for j in range(n):\n",
    "        total += y[j]/(2*H)\n",
    "    Y = 2*H*y[n]\n",
    "    for i in range(len(sites)):\n",
    "        k = sum(sites[:i])\n",
    "        p = sites[i]\n",
    "        ii = 0\n",
    "        z2 = 0\n",
    "        for j in range(k,k+l):\n",
    "            z2 += y[j+1]\n",
    "        df0a0 = -lamda[i][ii]*G(Y)*t-lamda[i][ii+1]*t*(1-z2)\n",
    "        df1a0 = lamda[i][ii+1]*t*(1-z2)\n",
    "        dfza0 = lamda[i][0]*G(Y)*t/(2*H)\n",
    "        dAL[k] = (A[L][k]+t*Adot[k]-f[k])*(1+t*Adotdot[k]/Adot[k]-df0a0)-(A[L][k+1]+t*Adot[k+1]-f[k+1])*df1a0-(A[L][n]+t*Adot[n]-f[n])*dfza0-penalty*(0.5-total)*t\n",
    "        \n",
    "        z2 = 0\n",
    "        for j in range(k+1, k+l+1):\n",
    "            z2 += y[j+1]\n",
    "        df0a1 = -lamda[i][ii]*G(Y)*t+lamda[i][ii+1]*y[k]*t\n",
    "        df1a1 = -lamda[i][ii+1]*y[k]*t-lamda[i][ii+2]*t*(1-z2)\n",
    "        df2a1 = lamda[i][ii+2]*t*(1-z2)\n",
    "        dfza1 = 1/(2*H)*lamda[i][0]*G(Y)*t\n",
    "        dAL[k+1] = -(A[L][k]+t*Adot[k]-f[k])*df0a1+(A[L][k+1]+t*Adot[k+1]-f[k+1])*(1+t*Adotdot[k+1]/Adot[k+1]-df1a1)-(A[L][k+2]+t*Adot[k+2]-f[k+2])*df2a1-(A[L][n]+t*Adot[n]-f[n])*dfza1-penalty*(0.5-total)*t\n",
    "        \n",
    "        for q in range(2, l):\n",
    "            dfa2L = [0 for i in range(q+2)]\n",
    "            dfa2R = [0 for i in range(q+2)]\n",
    "            dfa2L[0] = -lamda[i][ii]*G(Y)*t\n",
    "            dfa2R[0] = lamda[i][ii+1]*y[k]*t\n",
    "            for kk in range(1, len(dfa2L)-2):\n",
    "                dfa2L[kk] = -dfa2R[kk-1]\n",
    "                dfa2R[kk] = lamda[i][kk+1]*y[k+kk]*t\n",
    "            dfa2L[kk+1] = -dfa2R[kk]\n",
    "            z2 = 0\n",
    "            for j in range(k+q, k+q+l):\n",
    "                z2 += y[j+1]\n",
    "            dfa2R[kk+1] = -lamda[i][kk+2]*t*(1-z2)\n",
    "            dfa2L[kk+2] = -dfa2R[kk+1]\n",
    "            for o in range(len(dfa2L)):\n",
    "                if o != len(dfa2L)-2:\n",
    "                    dAL[k+q] += -(A[L][k+o]+t*Adot[k+o]-f[k+o])*(dfa2L[o]+dfa2R[o])\n",
    "                else:\n",
    "                    dAL[k+q] += (A[L][k+o]+t*Adot[k+o]-f[k+o])*(1+t*Adotdot[k+o]/Adot[k+o]-(dfa2L[o]+dfa2R[o]))\n",
    "            dAL[k+q] += -(A[L][n]+t*Adot[n]-f[n])*dfza0-penalty*(0.5-total)*t\n",
    "            \n",
    "        for q in range(l, p-l):\n",
    "            dfa3L = [0 for i in range(l+2)]\n",
    "            dfa3R = [0 for i in range(l+2)]\n",
    "            dfa3R[0] = lamda[i][ii+1]*y[k+ii]*t\n",
    "            for kk in range(1, l):\n",
    "                dfa3L[kk] = -dfa3R[kk]\n",
    "                dfa3R[kk] = lamda[i][kk+ii+1]*y[k+kk+ii]*t\n",
    "            dfa3L[l] = -dfa3R[l-1]\n",
    "            z2 = 0\n",
    "            for j in range(l):\n",
    "                z2 += y[k+q+j+1]\n",
    "            dfa3R[l] = -lamda[i][q+1]*t*(1-z2)\n",
    "            dfa3L[l+1] = -dfa3R[l]\n",
    "            for r in range(l+2):\n",
    "                if r!= l:\n",
    "                    dAL[k+q] += -(A[L][k+r+ii]+t*Adot[k+r+ii]-f[k+r+ii])*(dfa3L[r]+dfa3R[r])\n",
    "                if r == l:\n",
    "                    dAL[k+q] += (A[L][k+r+ii]+t*Adot[k+r+ii]-f[k+r+ii])*(1+t*Adotdot[k+r+ii]/Adot[k+r+ii]-(dfa3L[r]+dfa3R[r]))\n",
    "            dAL[k+q] += -penalty*(0.5-total)*t\n",
    "            ii += 1\n",
    "        dfa7R = [0 for i in range(l+2)]\n",
    "        dfa7L = [0 for i in range(l+2)]\n",
    "        dfa7R[0] = lamda[i][q-l+2]*y_hat[k+q-l+1]*t\n",
    "        for kk in range(1,l):\n",
    "            dfa7L[kk] = -dfa7R[kk-1]\n",
    "            dfa7R[kk] = lamda[i][q-l+2+kk]*y_hat[k+q-l+1+kk]*t\n",
    "        dfa7L[l] = -dfa7R[l-1]\n",
    "        dfa7R[l] = -lamda[i][q-l+2+kk+1]*t*np.ones_like(A[L][k+p-l]) \n",
    "        dfa7L[l+1] = -dfa7R[l]\n",
    "        for r in range(l+2):\n",
    "            if r!= l:\n",
    "                dAL[k+p-l] += -(A[L][k+r+ii]+t*Adot[k+r+ii]-f[k+r+ii])*(dfa7L[r]+dfa7R[r])\n",
    "            if r == l:\n",
    "                dAL[k+p-l] += (A[L][k+r+ii]+t*Adot[k+r+ii]-f[k+r+ii])*(1+t*Adotdot[k+r+ii]/Adot[k+r+ii]-(dfa7L[r]+dfa7R[r]))\n",
    "        dAL[k+p-l] += -penalty*(0.5-total)*t\n",
    "        ii += 1\n",
    "        \n",
    "        qq = 0\n",
    "        for q in range(p-l+1,p-1):\n",
    "            dfa12L = [0 for i in range(l+2-qq)]\n",
    "            dfa12R = [0 for i in range(l+2-qq)]\n",
    "            qq += 1\n",
    "            dfa12R[0] = lamda[i][q-l+1]*y_hat[k+q-l]*t\n",
    "            for kk in range(1,len(dfa12R)-3):\n",
    "                    dfa12L[kk] = -dfa12R[kk-1]\n",
    "                    dfa12R[kk] = lamda[i][q-l+kk+1]*y_hat[k+q-l+kk]*t\n",
    "            dfa12L[kk+1] = -dfa12R[kk]\n",
    "            dfa12R[kk+2] = -lamda[i][q+1]*t*np.ones_like(A[L][k+q])\n",
    "            dfa12L[kk+3] = -dfa12R[kk+2]\n",
    "            for r in range(len(dfa12R)-2):\n",
    "                dAL[k+q] += -(A[L][k+r+ii]+t*Adot[k+r+ii]-f[k+r+ii])*(dfa12L[r]+dfa12R[r])\n",
    "            dAL[k+q] += (A[L][k+q]+t*Adot[k+q]-f[k+q])*(1+t*Adotdot[k+q]/Adot[k+q]-(dfa12L[r+1]+dfa12R[r+1]))-(A[L][k+q+1]+t*Adot[k+q+1]-f[k+q+1])*(dfa12L[r+2]+dfa12R[r+2])-penalty*(0.5-total)*t\n",
    "            ii += 1\n",
    "        \n",
    "        df6a9 = lamda[i][p-l]*y[k+p-l-1]*t\n",
    "        df7a9 = -df6a9\n",
    "        df9a9 = -lamda[i][p]*t\n",
    "        dfza9 = 1/(2*H)*lamda[i][p]*t\n",
    "        dAL[k+p-1] = -(A[L][k+p-l-1]+t*Adot[k+p-l-1]-f[k+p-l-1])*df6a9-(A[L][k+p-l]+t*Adot[k+p-l]-f[k+p-l])*df7a9+(A[L][k+p-1]+t*Adot[k+p-1]-f[k+p-1])*(1+t*Adotdot[k+p-1]/Adot[k+p-1]-df9a9)-(A[L][n]+t*Adot[n]-f[n])*dfza9-penalty*(0.5-total)*t\n",
    "    s = 0\n",
    "    for i in range(len(sites)):\n",
    "        k = sum(sites[:i])\n",
    "        p = sites[i]\n",
    "        z1 = 0\n",
    "        for j in range(k, k+l):\n",
    "            z1 += y[j]\n",
    "        df0az = (lamda[i][0]*(1-z1)*Gprime(Y)*2*H*t)\n",
    "        s += -df0az\n",
    "        dAL[n] += -(A[L][k]+t*Adot[k]-f[k])*df0az\n",
    "    dAL[n] += (A[L][n]+t*Adot[n]-f[n])*(1+t*Adotdot[n]/Adot[n]-s)-penalty*2*H*(0.5-total)*t\n",
    "    dtAL = np.array(dAL).reshape((n+1,ntrain))/ntrain\n",
    "    for i in range(L-1,-1,-1):    \n",
    "        dZ[i] = dtAL*activation_derivative(Z[i],NA[i])\n",
    "        dW[i] = (dZ[i]@A[i].T)/ntrain\n",
    "        dB[i] = np.sum(dZ[i], axis = 1, keepdims = True)/ntrain\n",
    "        dtAL = (NW[i].T@dZ[i])/ntrain\n",
    "    return [dZ, dW, dB]    \n",
    "\n",
    "def rmsprop(NW, NB, dW, dB, SW, SB, epsilon, lr, beta):\n",
    "    for i in range(L):\n",
    "        SW[i] = (beta*SW[i]+(1-beta)*dW[i]**2)\n",
    "        SB[i] = (beta*SB[i]+(1-beta)*dB[i]**2)\n",
    "        NW[i] = NW[i]-lr*dW[i]/(SW[i]**0.5+epsilon)\n",
    "        NB[i] = NB[i]-lr*dB[i]/(SB[i]**0.5+epsilon)\n",
    "    return [NW, NB, SW, SB]\n",
    "\n",
    "def adam(i, NW, NB, dW, dB, VW, VB, SW, SB, epsilon, lr, momentum, beta):\n",
    "    VWhat = VW.copy()\n",
    "    VBhat = VB.copy()\n",
    "    SWhat = SW.copy()\n",
    "    SBhat = SB.copy()\n",
    "    for j in range(L):\n",
    "        VW[j] = momentum*VW[j]+(1-momentum)*dW[j]\n",
    "        VB[j] = momentum*VB[j]+(1-momentum)*dB[j]\n",
    "        SW[j] = beta*SW[j]+(1-beta)*(dW[j]**2)\n",
    "        SB[j] = beta*SB[j]+(1-beta)*(dB[j]**2)\n",
    "        VWhat[j] = VW[j]/(1-momentum**i)\n",
    "        VBhat[j] = VB[j]/(1-momentum**i)\n",
    "        SWhat[j] = SW[j]/(1-beta**i)\n",
    "        SBhat[j] = SB[j]/(1-beta**i)\n",
    "        NW[j] = NW[j]-lr*(VWhat[j]/np.sqrt(SWhat[j]+epsilon))\n",
    "        NB[j] = NB[j]-lr*(VBhat[j]/np.sqrt(SBhat[j]+epsilon))\n",
    "    return [NW, NB, VW, VB, SW, SB]\n",
    "\n",
    "def train_model(X, mean, epochs, NA, NW, NB, l, optimiser = 'sgd', loss = 'binary_cross_entropy', learning_rate = 0.001, \n",
    "                momentum = 0.9, epsilon = 10**-8, beta = 0.999, poolsize = 1, alpha = 1):\n",
    "    [dZ, dW, dB] = [[0 for i in range(L)],[0 for i in range(L)],[0 for i in range(L)]]\n",
    "    VW = [np.zeros(NW[i].shape) for i in range(L)]\n",
    "    VB = [np.zeros(NB[i].shape) for i in range(L)]\n",
    "    SW = [np.zeros(NW[i].shape) for i in range(L)]\n",
    "    SB = [np.zeros(NB[i].shape) for i in range(L)]\n",
    "    for i in range(epochs):\n",
    "        [Z, A] = forward_propagation(X, NA, NW, NB)\n",
    "        yhat = init+X[0]*(A[L])\n",
    "        f = funct(yhat, lamda, sites, l, poolsize, Tr[1])\n",
    "        [dZ, dW, dB] = backward_propagation(NA, NW, Z, A, dZ, dW, dB, Tr, yhat, f, sites, l, lamda, poolsize, alpha)\n",
    "        [NW, NB, VW, VB, SW, SB] =  adam(i+1, NW, NB, dW, dB, VW, VB, SW, SB, epsilon, learning_rate, momentum, beta)\n",
    "#         learning_rate = learning_rate*0.999**500\n",
    "        [NW, NB, SW, SB] = rmsprop(NW, NB, dW, dB, SW, SB, epsilon, learning_rate, beta)\n",
    "        if (i/epochs)*100 in range(100):\n",
    "            print('â–ˆ', end = '')\n",
    "    print('\\n')\n",
    "    return [NW, NB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a9e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3\n",
    "ensemblesize = 6\n",
    "# for ii in range(17,23):\n",
    "rn = [[] for j in range(p)]\n",
    "poolsize = 5\n",
    "alpha = 75\n",
    "densities1 = pd.DataFrame()\n",
    "densities2 = pd.DataFrame()\n",
    "for it in range(ensemblesize):\n",
    "    print(it+1, end = '.')\n",
    "    b = min(1/l,poolsize*(1/sum(sites)))\n",
    "    init = np.random.uniform(0, b, (p,1))\n",
    "    init[-1] = 0.5-1/(2*poolsize)*sum(init[:-1])\n",
    "    \n",
    "    [NA, NW, NB] = [[],[],[]]\n",
    "    add_layer(input_shape = 2, hidden_units = 2*p, activation = 'bps', initialiser = 'xavier')\n",
    "    for i in range(L-2):\n",
    "        add_layer(input_shape = 2*p, hidden_units = 2*p, activation = 'sigmoid', initialiser = 'xavier')\n",
    "    add_layer(input_shape = 2*p, hidden_units = p, activation = 'tanh', initialiser = 'xavier')\n",
    "    \"\"\"\n",
    "    Training the CDNN on the train set\n",
    "    \"\"\"\n",
    "    [NW, NB] = train_model(Tr, np.mean(init.T), 27000, NA, NW, NB, l, optimiser = 'rmsprop',\n",
    "                                     learning_rate = 10**-3, momentum = 0.9, beta = 0.999, poolsize = poolsize, alpha = alpha)\n",
    "    \"\"\"\n",
    "    Obtaining the solutions on the test set\n",
    "    \"\"\"\n",
    "    [Z,A] = forward_propagation(Te, NA, NW, NB)\n",
    "    v_hat = (init+Te[0]*(A[L]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
