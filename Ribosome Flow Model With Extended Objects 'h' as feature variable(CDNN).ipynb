{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b4763",
   "metadata": {
    "id": "626b4763"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib as mpl\n",
    "import matplotlib\n",
    "mpl.rcParams['ytick.labelsize'] = 13\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e222db9",
   "metadata": {
    "id": "9e222db9",
    "outputId": "43cfc2c2-1f2c-4adc-de6b-17904d2307aa"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setting up the parameters of the RFMEONP\n",
    "\"\"\"\n",
    "sites = [10,20,40]#Specifies the number of sites in each rfmeo in the network\n",
    "lamda1 = [1.0-(i)/20 for i in range(11)]#Parameters of the RFMEO 1\n",
    "lamda2= [1.0-(i)/30 for i in range(21)]#Parameters of the RFMEO 2\n",
    "lamda3 = [1.0-(i)/50 for i in range(41)]#Paramets of the RFMEO 3\n",
    "lamda = [lamda1, lamda2, lamda3]\n",
    "p = sum(sites)+1#Sum of sites in each rfmeo plus the pooling function\n",
    "l = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1eea3d",
   "metadata": {
    "id": "3e1eea3d",
    "outputId": "74ddd134-3016-42f3-bdac-c362070cdd88"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training data incorporating the free variable h alongwith the time variable\n",
    "\"\"\"\n",
    "h = 0.1\n",
    "h1 = 0.1\n",
    "t = np.arange(0, 1+h, h)\n",
    "H = np.array([0.05]+np.arange(0.1, 1+h1, h1).tolist())\n",
    "Tr = []\n",
    "for j in range(len(H)):\n",
    "    for i in range(len(t)):\n",
    "        Tr.append([t[i],H[j]])\n",
    "Tr = np.array(Tr).T\n",
    "ntrain = Tr.shape[1]\n",
    "\"\"\"\n",
    "Testing data incorporating the free variable h alongwith the time variable\n",
    "\"\"\" \n",
    "h = 0.0001\n",
    "h1 = 0.005\n",
    "t0 = np.arange(0, 1+h, h)\n",
    "H0 = np.arange(0.05, 1+h1, h1)\n",
    "# H0 = np.arange(0.1, 1+h1, h1)\n",
    "Te = []\n",
    "for j in range(len(H0)):\n",
    "    for i in range(len(t0)):\n",
    "        Te.append([t0[i],H0[j]])\n",
    "Te = np.array(Te).T\n",
    "ntest = Te.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee5fe91",
   "metadata": {
    "id": "2ee5fe91"
   },
   "outputs": [],
   "source": [
    "scale = 10000\n",
    "\n",
    "def G(Z):\n",
    "    return Z\n",
    "\n",
    "def Gprime(Z):\n",
    "    return 1.0\n",
    "\n",
    "def funct(y, lamda, sites, H):\n",
    "    f = y.copy()\n",
    "    n = sum(sites)\n",
    "    sites0 = 0\n",
    "    sitesn = 0\n",
    "    ii = 0\n",
    "    z = 2*H*y[n]\n",
    "    for i in range(len(sites)):\n",
    "        k = sum(sites[:i])\n",
    "        p = sites[i]\n",
    "        ii = 0\n",
    "        f[k] = lamda[i][ii]*G(z)*(1-y[k])-lamda[i][ii+1]*y[k]*(1-y[k+1])\n",
    "        sites0 += lamda[i][ii]*G(z)*(1-y[k])\n",
    "        ii += 1\n",
    "        for j in range(k+1, k+p-1):\n",
    "            f[j] = lamda[i][ii]*y[j-1]*(1-y[j])-lamda[i][ii+1]*y[j]*(1-y[j+1])\n",
    "            ii += 1\n",
    "        f[k+p-1] = lamda[i][ii]*y[k+p-2]*(1-y[k+p-1])-lamda[i][ii+1]*y[k+p-1]\n",
    "        sitesn += lamda[i][ii+1]*y[k+p-1]\n",
    "    f[n] = 1/(2*H)*(sitesn-sites0)\n",
    "    return scale*f\n",
    "\n",
    "def init_weights_biases(initialiser, N0, N1):\n",
    "    if initialiser.upper() == 'NORMAL':\n",
    "        return [np.random.normal(0,np.sqrt(2/N1),(N1,N0)), np.random.normal(0, np.sqrt(2/N1), (N1,1))]\n",
    "    if initialiser.upper() == 'UNIFORM':\n",
    "        return [np.random.uniform(0,0.05,(N1,N0)),np.random.uniform(0,0.05,(N1,1))]\n",
    "    if initialiser.upper() == 'XAVIER':\n",
    "        return [np.random.uniform(0, 1/np.sqrt(N1), (N1,N0)), np.random.normal(0, 1/np.sqrt(N1), (N1,1))]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def add_layer(input_shape, hidden_units , activation = 'sigmoid', initialiser = 'normal'):\n",
    "    weights_biases = init_weights_biases(initialiser, input_shape, hidden_units)\n",
    "    NA.append(activation)\n",
    "    NW.append(weights_biases[0])\n",
    "    NB.append(weights_biases[1])\n",
    "    return None\n",
    "\n",
    "def activation_function(x, string, alpha = 0.01):\n",
    "    if string.upper() == 'SIGMOID':\n",
    "        return (1/(1+np.exp(-x)))\n",
    "    if string.upper() == 'BPS':\n",
    "        return  2*(1/(1+np.exp(-x)))-1\n",
    "    if string.upper() == 'TRIG' or string.upper() == 'TRIGNOMETRIC':\n",
    "        return np.cos(x)\n",
    "    if string.upper() == 'CUSTOM':\n",
    "        return 0.9*np.tanh(x)-0.5*(1/(1+np.exp(-x)))\n",
    "    if string.upper() == 'TANH':\n",
    "        return np.tanh(x)\n",
    "    if string.upper() == 'RELU':\n",
    "        return (x+np.abs(x))\n",
    "    if string.upper() == 'LEAKYRELU' or string.upper() == 'LR':\n",
    "        return (x+alpha*x+np.abs(x-alpha*x))/2\n",
    "    if string.upper() == 'LINEAR':\n",
    "        return x\n",
    "    if string.upper() == 'EXPONENTIAL' or string.upper() == 'EXP':\n",
    "        return np.exp(x)\n",
    "    if string.upper() == 'ELU':\n",
    "        x[x<0] = 0.01*(np.exp(x[x<0])-1)\n",
    "        return x\n",
    "    if string.upper() == 'EXP':\n",
    "        return np.exp(-x)\n",
    "    return None\n",
    "\n",
    "def activation_derivative(x, string, alpha = 0.01):\n",
    "    if string.upper() == 'SIGMOID':\n",
    "        return (1/(1+np.exp(-x)))*(1-(1/(1+np.exp(-x))))\n",
    "    if string.upper() == 'BPS':\n",
    "        return 2*(1/(1+np.exp(-x)))*(1-(1/(1+np.exp(-x))))\n",
    "    if string.upper() == 'TRIG' or string.upper() == 'TRIGNOMETRIC':\n",
    "        return -np.sin(x)\n",
    "    if string.upper() == 'TANH':\n",
    "        return (1-np.tanh(x)**2)\n",
    "    if string.upper() == \"RELU\":\n",
    "        x[x>=0] = 1\n",
    "        x[x<0] = 0\n",
    "        return x\n",
    "    if string.upper() == 'CUSTOM':\n",
    "        return 0.9*(1-np.tanh(2*x)**2)-0.5*(1/(1+np.exp(-x)))*(1-(1/(1+np.exp(-x))))\n",
    "    if string.upper() == 'LEAKYRELU' or string.upper() == 'LR':\n",
    "        dx = np.ones(x.shape)\n",
    "        dx[x < 0] = alpha\n",
    "        x = dx.copy()\n",
    "        return x\n",
    "    if string.upper() == 'LINEAR':\n",
    "        x = 1\n",
    "        return x\n",
    "    if string.upper() == 'EXPONENTIAL' or string.upper() == 'EXP':\n",
    "        return np.exp(x)\n",
    "    if string.upper() == 'ELU':\n",
    "        x[x>=0] = 1\n",
    "        x[x<0] = 0.01*(np.exp(x[x<0]))\n",
    "        return x\n",
    "    if string.upper() == 'EXP':\n",
    "        return -np.exp(-x)\n",
    "    return None\n",
    "\n",
    "def forward_propagation(X,NA,NW,NB):\n",
    "    A = [X]\n",
    "    Z = []\n",
    "    for i in range(len(NA)):\n",
    "        Zstar = (NW[i]@A[i]+NB[i])\n",
    "        Astar = activation_function(Zstar.astype(float), NA[i])\n",
    "        Z.append(Zstar.astype(float))\n",
    "        A.append(Astar)\n",
    "    return([Z,A])\n",
    "\n",
    "def backward_propagation(NA, NW, Z, A, dZ, dW, dB, T, y, f, sites, lamda, alpha):\n",
    "    Adot = (np.gradient(A[L], 0.1)[0]/scale)-10**-10\n",
    "    Adotdot = (np.gradient(Adot, 0.1)[0]/scale)\n",
    "    dAL = [0 for i in range(sum(sites)+1)]\n",
    "    n = sum(sites)\n",
    "    H = 20*T[1]#Upscaling the second feature variable (h) to lie in the range of 1 to 20.\n",
    "    Y = 2*H*y[n]\n",
    "    total = y[n]\n",
    "    penalty = alpha#Penalty parameter for COP Loss\n",
    "    t = T[0]\n",
    "\n",
    "    for j in range(n):\n",
    "        total += y[j]/(2*H)\n",
    "    for i in range(len(sites)):\n",
    "        k = sum(sites[:i])\n",
    "        p = sites[i]\n",
    "        ii = 0\n",
    "        df0a0 = -lamda[i][ii]*G(Y)*t-lamda[i][ii+1]*t*(1-y[k+1])\n",
    "        df1a0 = lamda[i][ii+1]*t*(1-y[k+1])\n",
    "        dfza0 = +1/(2*H)*lamda[i][0]*G(Y)*t\n",
    "        dAL[k] = (A[L][k]+t*Adot[k]-f[k])*(1+t*Adotdot[k]/Adot[k]-df0a0)-(A[L][k+1]+t*Adot[k+1]-f[k+1])*df1a0-(A[L][n]+t*Adot[n]-f[n])*dfza0-penalty*(0.5-total)*t\n",
    "        ii += 1\n",
    "\n",
    "        for j in range(k+1, k+p-1):\n",
    "            df0a1 = lamda[i][ii]*y[j-1]*t\n",
    "            df1a1 = -lamda[i][ii]*y[j-1]*t-lamda[i][ii+1]*t*(1-y[j+1])\n",
    "            df2a1 = lamda[i][ii+1]*t*(1-y[j+1])\n",
    "            dAL[j] = -(A[L][j-1]+t*Adot[j-1]-f[j-1])*df0a1+(A[L][j]+t*Adot[j]-f[j])*(1+t*Adotdot[j]/Adot[j]-df1a1)-(A[L][j+1]+t*Adot[j+1]-f[j+1])*df2a1-penalty*(0.5-total)*t\n",
    "            ii += 1\n",
    "\n",
    "        df4a5 = lamda[i][ii]*y[ii-1]*t\n",
    "        df5a5 = -lamda[i][ii]*y[ii-1]*t-lamda[i][ii+1]*t\n",
    "        dfza5 = 1/(2*H)*lamda[i][ii+1]*t\n",
    "        dAL[k+p-1] = (-(A[L][k+p-2]+t*Adot[k+p-2]-f[k+p-2])*df4a5+(A[L][k+p-1]+t*Adot[k+p-1]-f[k+p-1])*(1+t*Adotdot[k+p-1]/Adot[k+p-1]-df5a5)-(A[L][n]+t*Adot[n]-f[n])*dfza5)-penalty*(0.5-total)*t\n",
    "    s = 0\n",
    "    for i in range(len(sites)):\n",
    "        k = sum(sites[:i])\n",
    "        df0az = lamda[i][0]*(1-y[k])*Gprime(Y)*2*H*t\n",
    "        s += -df0az\n",
    "        dAL[n] += -(A[L][k]+t*Adot[k]-f[k])*df0az\n",
    "    dAL[n] += ((A[L][n]+t*Adot[n]-f[n])*(1+t*Adotdot[n]/Adot[n]-s))-2*H*penalty*(0.5-total)*t\n",
    "    dtAL = np.array(dAL).reshape((sum(sites)+1,ntrain))/ntrain\n",
    "    for i in range(L-1,-1,-1):\n",
    "        dZ[i] = dtAL*activation_derivative(Z[i],NA[i])\n",
    "        dW[i] = (dZ[i]@A[i].T)/ntrain\n",
    "        dB[i] = np.sum(dZ[i], axis = 1, keepdims = True)/ntrain\n",
    "        dtAL = (NW[i].T@dZ[i])/ntrain\n",
    "    return [dZ, dW, dB]\n",
    "\n",
    "def rmsprop(NW, NB, dW, dB, SW, SB, epsilon, lr, beta):\n",
    "    for i in range(L):\n",
    "        SW[i] = (beta*SW[i]+(1-beta)*dW[i]**2)\n",
    "        SB[i] = (beta*SB[i]+(1-beta)*dB[i]**2)\n",
    "        NW[i] = NW[i]-lr*dW[i]/(SW[i]**0.5+epsilon)\n",
    "        NB[i] = NB[i]-lr*dB[i]/(SB[i]**0.5+epsilon)\n",
    "    return [NW, NB, SW, SB]\n",
    "\n",
    "def adam(i, NW, NB, dW, dB, VW, VB, SW, SB, epsilon, lr, momentum, beta):\n",
    "    VWhat = VW.copy()\n",
    "    VBhat = VB.copy()\n",
    "    SWhat = SW.copy()\n",
    "    SBhat = SB.copy()\n",
    "    for j in range(L):\n",
    "        VW[j] = momentum*VW[j]+(1-momentum)*dW[j]\n",
    "        VB[j] = momentum*VB[j]+(1-momentum)*dB[j]\n",
    "        SW[j] = beta*SW[j]+(1-beta)*(dW[j]**2)\n",
    "        SB[j] = beta*SB[j]+(1-beta)*(dB[j]**2)\n",
    "        VWhat[j] = VW[j]/(1-momentum**i)\n",
    "        VBhat[j] = VB[j]/(1-momentum**i)\n",
    "        SWhat[j] = SW[j]/(1-beta**i)\n",
    "        SBhat[j] = SB[j]/(1-beta**i)\n",
    "        NW[j] = NW[j]-lr*(VWhat[j]/np.sqrt(SWhat[j]+epsilon))\n",
    "        NB[j] = NB[j]-lr*(VBhat[j]/np.sqrt(SBhat[j]+epsilon))\n",
    "    return [NW, NB, VW, VB, SW, SB]\n",
    "\n",
    "def train_model(X, mean, epochs, NA, NW, NB, init, optimiser = 'sgd', loss = 'binary_cross_entropy', learning_rate = 0.001,\n",
    "                momentum = 0.9, epsilon = 10**-8, beta = 0.999, alpha = 1):\n",
    "    [dZ, dW, dB] = [[0 for i in range(L)],[0 for i in range(L)],[0 for i in range(L)]]\n",
    "    VW = [np.zeros(NW[i].shape) for i in range(L)]\n",
    "    VB = [np.zeros(NB[i].shape) for i in range(L)]\n",
    "    SW = [np.zeros(NW[i].shape) for i in range(L)]\n",
    "    SB = [np.zeros(NB[i].shape) for i in range(L)]\n",
    "    for i in range(epochs):\n",
    "        [Z, A] = forward_propagation(X, NA, NW, NB)\n",
    "        yhat = init+Tr[0]*(A[L])\n",
    "        f = funct(yhat, lamda, sites, Tr[1])\n",
    "        [dZ, dW, dB] = backward_propagation(NA, NW, Z, A, dZ, dW, dB, Tr, yhat, f, sites, lamda, alpha)\n",
    "        [NW, NB, SW, SB] = rmsprop(NW, NB, dW, dB, SW, SB, epsilon, learning_rate, beta)\n",
    "        if (i/epochs)*100 in range(100):\n",
    "            print('█', end = '')\n",
    "    print('\\n')\n",
    "    return [NW, NB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a802ed",
   "metadata": {
    "id": "78a802ed",
    "outputId": "15d509ce-caa9-45d4-ffd7-b8d635e8cd71"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training and Testing the Network\n",
    "\"\"\"\n",
    "L = 3 #Number of Hidden Layers\n",
    "ensemblesize = 5\n",
    "count = 0\n",
    "alpha = 310 #penalty parameter for the COP Loss\n",
    "densities = [[], [], []]\n",
    "for it in range(ensemblesize):\n",
    "    print(it+1, end = '.')\n",
    "    plt.figure(figsize = (15,7))\n",
    "    init = np.random.uniform(0, 0, (p,1))\n",
    "    init[-1] = 0.5\n",
    "    [NA, NW, NB] = [[],[],[]]\n",
    "    add_layer(input_shape = 2, hidden_units = 2*p, activation = 'bps', initialiser = 'xavier')\n",
    "    for i in range(L-2):\n",
    "        add_layer(input_shape = 2*p, hidden_units = 3*p, activation = 'sigmoid', initialiser = 'xavier')\n",
    "    add_layer(input_shape = 3*p, hidden_units = p, activation = 'bps', initialiser = 'xavier')\n",
    "    import time\n",
    "    toc = time.time()\n",
    "    iter = 0\n",
    "    cost = 10**100\n",
    "    \"\"\"\n",
    "    Training the model on the training set\n",
    "    \"\"\"\n",
    "    [NW, NB] = train_model(Tr, np.mean(init.T), 27500, NA, NW, NB, init, optimiser = 'rmsprop',\n",
    "                                     learning_rate = 10**-3, momentum = 0.9, beta = 0.999, alpha = alpha)\n",
    "    tic = time.time()\n",
    "    print('\\nModel Training Time:',str((tic-toc))+' seconds')\n",
    "    \"\"\"\n",
    "    Obtaining the solutions on the test set\n",
    "    \"\"\"\n",
    "    [Z,A] = forward_propagation(Te, NA, NW, NB)\n",
    "    v_hat = init+Te[0]*(A[L])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
