{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a1fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pylab import *\n",
    "rc('axes', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d6da69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setting up the parameters of the RFMEONP\n",
    "\"\"\"\n",
    "sites = [7,5]#Number of sites in each RFMEO\n",
    "lamda1 = np.ones(8)#Parameters of RFMEO 1\n",
    "lamda2 = np.ones(6)#Parameters of RFMEO 2\n",
    "lamda = np.array([lamda1,lamda2])\n",
    "l = 1 #site size\n",
    "p = sum(sites)+1#Total Number of sites in each rfmeo in the network plus the pooling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e0c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generating the Training and Test Sets\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Training Set Generation\n",
    "\"\"\"\n",
    "h = 0.1#Training Step Size\n",
    "t = np.arange(0,1+h, h)\n",
    "Xtr = t.reshape(1,len(t))\n",
    "ntrain = Xtr.shape[1]# Number of training samples\n",
    "\n",
    "\"\"\"\n",
    "Testing Set Generation\n",
    "\"\"\"\n",
    "h = 0.0001#Testing Step Size\n",
    "t0 = np.arange(0, 0.9+h, h)\n",
    "Xte = t0.reshape(1, len(t0))\n",
    "ntest = Xte.shape[1]#Number of testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d992161",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generating the Training and Test Sets\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Training Set Generation\n",
    "\"\"\"\n",
    "h = 0.1#Training Step Size\n",
    "t = np.arange(0,1+h, h)\n",
    "Xtr = t.reshape(1,len(t))\n",
    "n = Xtr.shape[1]#Number of training samples\n",
    "\n",
    "\"\"\"\n",
    "Testing Set Generation\n",
    "\"\"\"\n",
    "h = 0.0001#Testing Step Size\n",
    "t0 = np.arange(0, 0.9+h, h)\n",
    "Xte = t0.reshape(1, len(t0))\n",
    "nprime = Xte.shape[1]#Number of testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a1742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Governing system of ODE\n",
    "\"\"\"\n",
    "scale = 10000 # Scaling parameter for the system of ode\n",
    "\n",
    "def G(Z):\n",
    "    return Z\n",
    "\n",
    "def Gprime(Z):\n",
    "    return 1.0\n",
    "\n",
    "def funct(y, lamda, sites, l, H):\n",
    "    f = y.copy()\n",
    "    n = sum(sites)\n",
    "    Y = 2*H*y[n]\n",
    "    if l>1:\n",
    "        for i in range(len(sites)):\n",
    "            k = int(sum(sites[:i]))\n",
    "            p = sites[i]\n",
    "            ii = 0\n",
    "            z1 = 0\n",
    "            z2 = 0\n",
    "            for j in range(k, k+l):\n",
    "                z1 += y[j]\n",
    "                z2 += y[j+1]\n",
    "            f[k] = lamda[i][ii]*G(Y)*(1-z1)-lamda[i][ii+1]*y[k]*(1-z2)\n",
    "\n",
    "            ii += 1\n",
    "\n",
    "            for tt in range(k+1, k+p-l):\n",
    "                z1 = 0\n",
    "                z2 = 0\n",
    "                for j in range(tt, tt+l):\n",
    "                    z1 += y[j]\n",
    "                    z2 += y[j+1]\n",
    "                f[tt] = lamda[i][ii]*y[tt-1]*(1-z1)-lamda[i][ii+1]*y[tt]*(1-z2)#verify\n",
    "                ii += 1\n",
    "    #         print(z2)\n",
    "            f[k+p-l] = lamda[i][ii]*y[tt]*(1-z2)-lamda[i][ii+1]*y[k+p-l]\n",
    "            ii += 1\n",
    "\n",
    "            for kk in range(k+p-l+1, k+p):\n",
    "                f[kk] = lamda[i][ii]*y[kk-1]-lamda[i][ii+1]*y[kk]\n",
    "                ii += 1\n",
    "\n",
    "    #         sitesn += lamda[i][ii]*y[k+p-1]\n",
    "        sites0 = 0\n",
    "        sitesn = 0\n",
    "        for i in range(len(sites)):\n",
    "            k = int(sum(sites[:i]))\n",
    "            p = sites[i]\n",
    "            z1 = 0\n",
    "            for j in range(k,k+l):\n",
    "                z1 += y[j]\n",
    "            sites0 += lamda[i][0]*G(Y)*(1-z1)\n",
    "            sitesn += lamda[i][p]*y[k+p-1]\n",
    "        f[n] = 1/(2*H)*(sitesn-sites0)\n",
    "    else:\n",
    "        sites0 = 0\n",
    "        sitesn = 0\n",
    "        ii = 0\n",
    "        z = 2*H*y[n]\n",
    "        for i in range(len(sites)):\n",
    "            k = int(sum(sites[:i]))\n",
    "            p = sites[i]\n",
    "            ii = 0\n",
    "            f[k] = lamda[i][ii]*G(z)*(1-y[k])-lamda[i][ii+1]*y[k]*(1-y[k+1])\n",
    "            sites0 += lamda[i][ii]*G(z)*(1-y[k])\n",
    "            ii += 1\n",
    "            for j in range(k+1, k+p-1):\n",
    "                f[j] = lamda[i][ii]*y[j-1]*(1-y[j])-lamda[i][ii+1]*y[j]*(1-y[j+1])\n",
    "                ii += 1\n",
    "            f[k+p-1] = lamda[i][ii]*y[k+p-2]*(1-y[k+p-1])-lamda[i][ii+1]*y[k+p-1]\n",
    "            sitesn += lamda[i][ii+1]*y[k+p-1]\n",
    "        f[n] = 1/(2*H)*(sitesn-sites0)\n",
    "    return scale*f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84f39488",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setting Up the Neural Network for ODE\n",
    "\"\"\"\n",
    "\n",
    "def init_weights_biases(initialiser, N0, N1):\n",
    "    if initialiser.upper() == 'NORMAL':\n",
    "        return [np.random.normal(0,np.sqrt(2/N1),(N1,N0)), np.random.normal(0, np.sqrt(2/N1), (N1,1))]\n",
    "    if initialiser.upper() == 'UNIFORM':\n",
    "        return [np.random.uniform(0,np.sqrt(2/N1),(N1,N0)),np.random.uniform(0,0.05,(N1,1))]\n",
    "    if initialiser.upper() == 'XAVIER':\n",
    "        return [np.random.uniform(0, 1/np.sqrt(N1), (N1,N0)), np.random.normal(0, 1/np.sqrt(N1), (N1,1))]\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def add_layer(input_shape, hidden_units , activation = 'sigmoid', initialiser = 'normal'): \n",
    "    weights_biases = init_weights_biases(initialiser, input_shape, hidden_units)\n",
    "    NA.append(activation)\n",
    "    NW.append(weights_biases[0])\n",
    "    NB.append(weights_biases[1])\n",
    "    return None\n",
    "\n",
    "def activation_function(x, string, alpha = 0.01):\n",
    "    if string.upper() == 'SIGMOID':\n",
    "        return (1/(1+np.exp(-x)))\n",
    "    if string.upper() == 'BPS':\n",
    "        return  2*(1/(1+np.exp(-x)))-1\n",
    "    if string.upper() == 'TRIG' or string.upper() == 'TRIGNOMETRIC':\n",
    "        return np.cos(x)\n",
    "    if string.upper() == 'CUSTOM':\n",
    "        return 0.9*np.tanh(x)-0.5*(1/(1+np.exp(-x)))\n",
    "    if string.upper() == 'TANH':\n",
    "        return np.tanh(x)\n",
    "    if string.upper() == 'RELU':\n",
    "        return (x+np.abs(x))/2\n",
    "    if string.upper() == 'LEAKYRELU' or string.upper() == 'LR':\n",
    "        return (x+alpha*x+np.abs(x-alpha*x))/2\n",
    "    if string.upper() == 'LINEAR':\n",
    "        return x\n",
    "    if string.upper() == 'EXPONENTIAL' or string.upper() == 'EXP':\n",
    "        return np.exp(x)\n",
    "    if string.upper() == 'ELU':\n",
    "        x[x<0] = 0.01*(np.exp(x[x<0])-1)\n",
    "        return x\n",
    "    if string.upper() == 'EXP':\n",
    "        return np.exp(-x)\n",
    "    return None\n",
    "    \n",
    "def activation_derivative(x, string, alpha = 0.01):\n",
    "    if string.upper() == 'SIGMOID':\n",
    "        return (1/(1+np.exp(-x)))*(1-(1/(1+np.exp(-x))))\n",
    "    if string.upper() == 'BPS':\n",
    "        return 2*(1/(1+np.exp(-x)))*(1-(1/(1+np.exp(-x))))\n",
    "    if string.upper() == 'TRIG' or string.upper() == 'TRIGNOMETRIC':\n",
    "        return -np.sin(x)\n",
    "    if string.upper() == 'TANH':\n",
    "        return (1-np.tanh(x)**2)\n",
    "    if string.upper() == \"RELU\":\n",
    "        x[x<0] = 0\n",
    "        x[x>=0] = 1\n",
    "        return x\n",
    "    if string.upper() == 'CUSTOM':\n",
    "        return 0.9*(1-np.tanh(2*x)**2)-0.5*(1/(1+np.exp(-x)))*(1-(1/(1+np.exp(-x))))\n",
    "    if string.upper() == 'LEAKYRELU' or string.upper() == 'LR':\n",
    "        dx = np.ones(x.shape)\n",
    "        dx[x < 0] = alpha\n",
    "        x = dx.copy()\n",
    "        return x\n",
    "    if string.upper() == 'LINEAR':\n",
    "        x = 1\n",
    "        return x\n",
    "    if string.upper() == 'EXPONENTIAL' or string.upper() == 'EXP':\n",
    "        return np.exp(x)\n",
    "    if string.upper() == 'ELU':\n",
    "        x[x>=0] = 1\n",
    "        x[x<0] = 0.01*(np.exp(x[x<0]))\n",
    "        return x\n",
    "    if string.upper() == 'EXP':\n",
    "        return -np.exp(-x)\n",
    "    return None\n",
    "    \n",
    "def forward_propagation(X,NA,NW,NB):\n",
    "    A = [X]\n",
    "    Z = []\n",
    "    for i in range(len(NA)):\n",
    "        Zstar = (NW[i]@A[i]+NB[i])\n",
    "        Astar = activation_function(Zstar.astype(float), NA[i])\n",
    "        Z.append(Zstar.astype(float))\n",
    "        A.append(Astar)\n",
    "    return([Z,A])\n",
    "\n",
    "def backward_propagation(NA, NW, Z, A, dZ, dW, dB, y_hat, f, H, sites, l, lamda, alpha):\n",
    "    Adot = (np.gradient(A[L],0.1)[0]/scale)-10**-10\n",
    "    Adotdot = (np.gradient(Adot,0.1)[0]/scale)\n",
    "    dAL = [0 for i in range(sum(sites)+1)]\n",
    "    y = y_hat.copy()\n",
    "    n = sum(sites)\n",
    "    if l>1:\n",
    "        sites0 = 0\n",
    "        total = y[n]\n",
    "        penalty = alpha#Tuning parameter for the COP Loss\n",
    "        penalty2 = 1\n",
    "        for j in range(n):\n",
    "            total += y[j]/(2*H)\n",
    "        Y = 2*H*y[n]\n",
    "        for i in range(len(sites)):\n",
    "            k = int(sum(sites[:i]))\n",
    "            p = sites[i]\n",
    "            ii = 0\n",
    "            z2 = 0\n",
    "            for j in range(k,k+l):\n",
    "                z2 += y[j+1]\n",
    "            df0a0 = -lamda[i][ii]*G(Y)*t-lamda[i][ii+1]*t*(1-z2)\n",
    "            df1a0 = lamda[i][ii+1]*t*(1-z2)\n",
    "            dfza0 = lamda[i][0]*G(Y)*t/(2*H)\n",
    "            dAL[k] = (A[L][k]+t*Adot[k]-f[k])*(1+t*Adotdot[k]/Adot[k]-df0a0)-(A[L][k+1]+t*Adot[k+1]-f[k+1])*df1a0-(A[L][n]+t*Adot[n]-f[n])*dfza0-penalty*(0.5-total)*t\n",
    "\n",
    "            z2 = 0\n",
    "            for j in range(k+1, k+l+1):\n",
    "                z2 += y[j+1]\n",
    "            df0a1 = -lamda[i][ii]*G(Y)*t+lamda[i][ii+1]*y[k]*t\n",
    "            df1a1 = -lamda[i][ii+1]*y[k]*t-lamda[i][ii+2]*t*(1-z2)\n",
    "            df2a1 = lamda[i][ii+2]*t*(1-z2)\n",
    "            dfza1 = 1/(2*H)*lamda[i][0]*G(Y)*t\n",
    "            dAL[k+1] = -(A[L][k]+t*Adot[k]-f[k])*df0a1+(A[L][k+1]+t*Adot[k+1]-f[k+1])*(1+t*Adotdot[k+1]/Adot[k+1]-df1a1)-(A[L][k+2]+t*Adot[k+2]-f[k+2])*df2a1-(A[L][n]+t*Adot[n]-f[n])*dfza1-penalty*(0.5-total)*t\n",
    "\n",
    "            for q in range(2, l):\n",
    "                dfa2L = [0 for i in range(q+2)]\n",
    "                dfa2R = [0 for i in range(q+2)]\n",
    "                dfa2L[0] = -lamda[i][ii]*G(Y)*t\n",
    "                dfa2R[0] = lamda[i][ii+1]*y[k]*t\n",
    "                for kk in range(1, len(dfa2L)-2):\n",
    "                    dfa2L[kk] = -dfa2R[kk-1]\n",
    "                    dfa2R[kk] = lamda[i][kk+1]*y[k+kk]*t\n",
    "                dfa2L[kk+1] = -dfa2R[kk]\n",
    "                z2 = 0\n",
    "                for j in range(k+q, k+q+l):\n",
    "                    z2 += y[j+1]\n",
    "                dfa2R[kk+1] = -lamda[i][kk+2]*t*(1-z2)\n",
    "                dfa2L[kk+2] = -dfa2R[kk+1]\n",
    "                for o in range(len(dfa2L)):\n",
    "                    if o != len(dfa2L)-2:\n",
    "                        dAL[k+q] += -(A[L][k+o]+t*Adot[k+o]-f[k+o])*(dfa2L[o]+dfa2R[o])\n",
    "                    else:\n",
    "                        dAL[k+q] += (A[L][k+o]+t*Adot[k+o]-f[k+o])*(1+t*Adotdot[k+o]/Adot[k+o]-(dfa2L[o]+dfa2R[o]))\n",
    "                dAL[k+q] += -(A[L][n]+t*Adot[n]-f[n])*dfza0-penalty*(0.5-total)*t\n",
    "\n",
    "            for q in range(l, p-l):\n",
    "                dfa3L = [0 for i in range(l+2)]\n",
    "                dfa3R = [0 for i in range(l+2)]\n",
    "                dfa3R[0] = lamda[i][ii+1]*y[k+ii]*t\n",
    "                for kk in range(1, l):\n",
    "                    dfa3L[kk] = -dfa3R[kk]\n",
    "                    dfa3R[kk] = lamda[i][kk+ii+1]*y[k+kk+ii]*t\n",
    "                dfa3L[l] = -dfa3R[l-1]\n",
    "                z2 = 0\n",
    "                for j in range(l):\n",
    "                    z2 += y[k+q+j+1]\n",
    "                dfa3R[l] = -lamda[i][q+1]*t*(1-z2)\n",
    "                dfa3L[l+1] = -dfa3R[l]\n",
    "                for r in range(l+2):\n",
    "                    if r!= l:\n",
    "                        dAL[k+q] += -(A[L][k+r+ii]+t*Adot[k+r+ii]-f[k+r+ii])*(dfa3L[r]+dfa3R[r])\n",
    "                    if r == l:\n",
    "                        dAL[k+q] += (A[L][k+r+ii]+t*Adot[k+r+ii]-f[k+r+ii])*(1+t*Adotdot[k+r+ii]/Adot[k+r+ii]-(dfa3L[r]+dfa3R[r]))\n",
    "                dAL[k+q] += -penalty*(0.5-total)*t\n",
    "                ii += 1\n",
    "            dfa7R = [0 for i in range(l+2)]\n",
    "            dfa7L = [0 for i in range(l+2)]\n",
    "            dfa7R[0] = lamda[i][q-l+2]*y_hat[k+q-l+1]*t\n",
    "            for kk in range(1,l):\n",
    "                dfa7L[kk] = -dfa7R[kk-1]\n",
    "                dfa7R[kk] = lamda[i][q-l+2+kk]*y_hat[k+q-l+1+kk]*t\n",
    "            dfa7L[l] = -dfa7R[l-1]\n",
    "            dfa7R[l] = -lamda[i][q-l+2+kk+1]*t*np.ones_like(A[L][k+p-l]) \n",
    "            dfa7L[l+1] = -dfa7R[l]\n",
    "            for r in range(l+2):\n",
    "                if r!= l:\n",
    "                    dAL[k+p-l] += -(A[L][k+r+ii]+t*Adot[k+r+ii]-f[k+r+ii])*(dfa7L[r]+dfa7R[r])\n",
    "                if r == l:\n",
    "                    dAL[k+p-l] += (A[L][k+r+ii]+t*Adot[k+r+ii]-f[k+r+ii])*(1+t*Adotdot[k+r+ii]/Adot[k+r+ii]-(dfa7L[r]+dfa7R[r]))\n",
    "            dAL[k+p-l] += -penalty*(0.5-total)*t\n",
    "            ii += 1\n",
    "\n",
    "            qq = 0\n",
    "            for q in range(p-l+1,p-1):\n",
    "                dfa12L = [0 for i in range(l+2-qq)]\n",
    "                dfa12R = [0 for i in range(l+2-qq)]\n",
    "                qq += 1\n",
    "                dfa12R[0] = lamda[i][q-l+1]*y_hat[k+q-l]*t\n",
    "                for kk in range(1,len(dfa12R)-3):\n",
    "                        dfa12L[kk] = -dfa12R[kk-1]\n",
    "                        dfa12R[kk] = lamda[i][q-l+kk+1]*y_hat[k+q-l+kk]*t\n",
    "                dfa12L[kk+1] = -dfa12R[kk]\n",
    "                dfa12R[kk+2] = -lamda[i][q+1]*t*np.ones_like(A[L][k+q])\n",
    "                dfa12L[kk+3] = -dfa12R[kk+2]\n",
    "                for r in range(len(dfa12R)-2):\n",
    "                    dAL[k+q] += -(A[L][k+r+ii]+t*Adot[k+r+ii]-f[k+r+ii])*(dfa12L[r]+dfa12R[r])\n",
    "                dAL[k+q] += (A[L][k+q]+t*Adot[k+q]-f[k+q])*(1+t*Adotdot[k+q]/Adot[k+q]-(dfa12L[r+1]+dfa12R[r+1]))-(A[L][k+q+1]+t*Adot[k+q+1]-f[k+q+1])*(dfa12L[r+2]+dfa12R[r+2])-penalty*(0.5-total)*t\n",
    "                ii += 1\n",
    "\n",
    "            df6a9 = lamda[i][p-l]*y[k+p-l-1]*t\n",
    "            df7a9 = -df6a9\n",
    "            df9a9 = -lamda[i][p]*t\n",
    "            dfza9 = 1/(2*H)*lamda[i][p]*t\n",
    "            dAL[k+p-1] = -(A[L][k+p-l-1]+t*Adot[k+p-l-1]-f[k+p-l-1])*df6a9-(A[L][k+p-l]+t*Adot[k+p-l]-f[k+p-l])*df7a9+(A[L][k+p-1]+t*Adot[k+p-1]-f[k+p-1])*(1+t*Adotdot[k+p-1]/Adot[k+p-1]-df9a9)-(A[L][n]+t*Adot[n]-f[n])*dfza9-penalty*(0.5-total)*t\n",
    "        s = 0\n",
    "        for i in range(len(sites)):\n",
    "            k = int(sum(sites[:i]))\n",
    "            p = sites[i]\n",
    "            z1 = 0\n",
    "            for j in range(k, k+l):\n",
    "                z1 += y[j]\n",
    "            df0az = (lamda[i][0]*(1-z1)*Gprime(Y)*2*H*t)\n",
    "            s += -df0az\n",
    "            dAL[n] += -(A[L][k]+t*Adot[k]-f[k])*df0az\n",
    "        dAL[n] += (A[L][n]+t*Adot[n]-f[n])*(1+t*Adotdot[n]/Adot[n]-s)-penalty*2*H*(0.5-total)*t\n",
    "    else:\n",
    "        Y = 2*H*y[n]\n",
    "        total = y[n]\n",
    "        penalty = 200\n",
    "        penalty2 = 1\n",
    "        for j in range(n):\n",
    "            total += y[j]/(2*H)\n",
    "        for i in range(len(sites)):\n",
    "            k = int(sum(sites[:i]))\n",
    "            p = sites[i]\n",
    "            ii = 0\n",
    "            df0a0 = -lamda[i][ii]*G(Y)*t-lamda[i][ii+1]*t*(1-y[k+1])\n",
    "            df1a0 = lamda[i][ii+1]*t*(1-y[k+1])\n",
    "            dfza0 = +1/(2*H)*lamda[i][0]*G(Y)*t\n",
    "            dAL[k] = (A[L][k]+t*Adot[k]-f[k])*(1+t*Adotdot[k]/Adot[k]-df0a0)-(A[L][k+1]+t*Adot[k+1]-f[k+1])*df1a0-(A[L][n]+t*Adot[n]-f[n])*dfza0-penalty*(0.5-total)*t\n",
    "            ii += 1\n",
    "\n",
    "            for j in range(k+1, k+p-1):\n",
    "                df0a1 = lamda[i][ii]*y[j-1]*t\n",
    "                df1a1 = -lamda[i][ii]*y[j-1]*t-lamda[i][ii+1]*t*(1-y[j+1])\n",
    "                df2a1 = lamda[i][ii+1]*t*(1-y[j+1])\n",
    "                dAL[j] = -(A[L][j-1]+t*Adot[j-1]-f[j-1])*df0a1+(A[L][j]+t*Adot[j]-f[j])*(1+t*Adotdot[j]/Adot[j]-df1a1)-(A[L][j+1]+t*Adot[j+1]-f[j+1])*df2a1-penalty*(0.5-total)*t\n",
    "                ii += 1\n",
    "\n",
    "            df4a5 = lamda[i][ii]*y[ii-1]*t\n",
    "            df5a5 = -lamda[i][ii]*y[ii-1]*t-lamda[i][ii+1]*t\n",
    "            dfza5 = 1/(2*H)*lamda[i][ii+1]*t\n",
    "            dAL[k+p-1] = penalty2*(-(A[L][k+p-2]+t*Adot[k+p-2]-f[k+p-2])*df4a5+(A[L][k+p-1]+t*Adot[k+p-1]-f[k+p-1])*(1+t*Adotdot[k+p-1]/Adot[k+p-1]-df5a5)-(A[L][n]+t*Adot[n]-f[n])*dfza5)-penalty*(0.5-total)*t\n",
    "        s = 0\n",
    "        for i in range(len(sites)):\n",
    "            k = int(sum(sites[:i]))\n",
    "            df0az = lamda[i][0]*(1-y[k])\n",
    "            s += -df0az\n",
    "            dAL[n] += -penalty2*(A[L][k]+t*Adot[k]-f[k])*Gprime(Y)*t*df0az\n",
    "        dAL[n] += penalty2*((A[L][n]+t*Adot[n]-f[n])*(1+t*Adotdot[n]/Adot[n]-Gprime(Y)*2*H*t*s))-2*H*penalty*(0.5-total)*t\n",
    "    dtAL = np.array(dAL).reshape((n+1,ntrain))/ntrain\n",
    "    for i in range(L-1,-1,-1):    \n",
    "        dZ[i] = dtAL*activation_derivative(Z[i],NA[i])\n",
    "        dW[i] = (dZ[i]@A[i].T)/ntrain\n",
    "        dB[i] = np.sum(dZ[i], axis = 1, keepdims = True)/ntrain\n",
    "        dtAL = (NW[i].T@dZ[i])/ntrain\n",
    "    return [dZ, dW, dB]\n",
    "\n",
    "def rmsprop(NW, NB, dW, dB, SW, SB, epsilon, lr, beta):\n",
    "    for i in range(L):\n",
    "        SW[i] = (beta*SW[i]+(1-beta)*dW[i]**2)\n",
    "        SB[i] = (beta*SB[i]+(1-beta)*dB[i]**2)\n",
    "        NW[i] = NW[i]-lr*dW[i]/(SW[i]**0.5+epsilon)\n",
    "        NB[i] = NB[i]-lr*dB[i]/(SB[i]**0.5+epsilon)\n",
    "    return [NW, NB, SW, SB]\n",
    "\n",
    "def adam(i, NW, NB, dW, dB, VW, VB, SW, SB, epsilon, lr, momentum, beta):\n",
    "    VWhat = VW.copy()\n",
    "    VBhat = VB.copy()\n",
    "    SWhat = SW.copy()\n",
    "    SBhat = SB.copy()\n",
    "    for j in range(L):\n",
    "        VW[j] = momentum*VW[j]+(1-momentum)*dW[j]\n",
    "        VB[j] = momentum*VB[j]+(1-momentum)*dB[j]\n",
    "        SW[j] = beta*SW[j]+(1-beta)*(dW[j]**2)\n",
    "        SB[j] = beta*SB[j]+(1-beta)*(dB[j]**2)\n",
    "        VWhat[j] = VW[j]/(1-momentum**i)\n",
    "        VBhat[j] = VB[j]/(1-momentum**i)\n",
    "        SWhat[j] = SW[j]/(1-beta**i)\n",
    "        SBhat[j] = SB[j]/(1-beta**i)\n",
    "        NW[j] = NW[j]-lr*(VWhat[j]/np.sqrt(SWhat[j]+epsilon))\n",
    "        NB[j] = NB[j]-lr*(VBhat[j]/np.sqrt(SBhat[j]+epsilon))\n",
    "    return [NW, NB, VW, VB, SW, SB]\n",
    "\n",
    "def train_model(X, epochs, NA, NW, NB, optimiser = 'rmsprop', loss = 'binary_cross_entropy', learning_rate = 0.001, \n",
    "                momentum = 0.9, epsilon = 10**-8, beta = 0.999, l = 2, poolsize = 1, alpha = 1):\n",
    "    [dZ, dW, dB] = [[0 for i in range(L)],[0 for i in range(L)],[0 for i in range(L)]]\n",
    "    VW = [np.zeros(NW[i].shape) for i in range(L)]\n",
    "    VB = [np.zeros(NB[i].shape) for i in range(L)]\n",
    "    SW = [np.zeros(NW[i].shape) for i in range(L)]\n",
    "    SB = [np.zeros(NB[i].shape) for i in range(L)]\n",
    "    for i in range(epochs):\n",
    "        [Z, A] = forward_propagation(X, NA, NW, NB)\n",
    "        yhat = init+t*(A[L])\n",
    "        f = funct(yhat, lamda, sites, l, poolsize)\n",
    "        [dZ, dW, dB] = backward_propagation(NA, NW, Z, A, dZ, dW, dB, yhat, f, poolsize, sites, l, lamda, alpha)\n",
    "        if optimiser.upper() == 'RMSPROP':\n",
    "            [NW, NB, SW, SB] = rmsprop(NW, NB, dW, dB, SW, SB, epsilon, learning_rate, beta)\n",
    "        elif optimiser.upper() == 'ADAM':\n",
    "            [NW, NB, VW, VB, SW, SB] =  adam(i+1, NW, NB, dW, dB, VW, VB, SW, SB, epsilon, learning_rate, momentum, beta)\n",
    "        \n",
    "        if (i/epochs)*100 in range(100):\n",
    "            print('â–ˆ', end = '')\n",
    "#     print('\\n')\n",
    "    return [NW, NB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "011373fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training and Testing the Network\n",
    "\"\"\"\n",
    "ensemblesize = 6\n",
    "l = 2\n",
    "h = 2\n",
    "for it in range(ensemblesize):\n",
    "    plt.figure(figsize = (12, 5))\n",
    "    print(it+1, end = '.')\n",
    "    b = min(1/l, h*(1/sum(sites)))\n",
    "    init = np.random.uniform(0, b, (p,1))\n",
    "    init[-1] = 0.5-1/(2*h)*sum(init[:-1])\n",
    "    \n",
    "    [NA, NW, NB] = [[],[],[]]\n",
    "    add_layer(input_shape = 1, hidden_units = p, activation = 'bps', initialiser = 'xavier')\n",
    "    for i in range(L-2):\n",
    "        add_layer(input_shape = p, hidden_units = p, activation = 'sigmoid', initialiser = 'xavier')\n",
    "    add_layer(input_shape = p, hidden_units = p, activation = 'bps', initialiser = 'xavier')\n",
    "    \n",
    "    \"\"\"\n",
    "    Training the CDNN on the train set\n",
    "    \"\"\"\n",
    "    [NW, NB] = train_model(Xtr, 8000, NA, NW, NB, optimiser = 'rmsprop',\n",
    "                                     learning_rate = 10**-2, momentum = 0.9, beta = 0.999, l = l, poolsize = h, alpha = alpha)\n",
    "    [Z,A] = forward_propagation(Xte, NA, NW, NB)\n",
    "    \"\"\"\n",
    "    Obtaining the solutions on the test set\n",
    "    \"\"\"\n",
    "    vhat = (init+Xte*(A[L]))\n",
    "    for j in range(p):\n",
    "        plt.plot(t0.ravel(), vhat[j])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
