{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36bea99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "rc('axes', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9b8cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setting up the parameters of the RFMEO\n",
    "\"\"\"\n",
    "lamda = [1-i/10 for i in range(9)]#list of free parameters\n",
    "p = len(lamda)-1#Number of Sites\n",
    "l = 2#length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1699750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generating the Training and Test Sets\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Training Set Generation\n",
    "\"\"\"\n",
    "h = 0.1#training step size\n",
    "t = np.arange(0,1+h, h)\n",
    "Xtr = t.reshape(1,len(t))\n",
    "n = Xtr.shape[1]#Number of training samples\n",
    "\n",
    "\"\"\"\n",
    "Testing Set Generation\n",
    "\"\"\"\n",
    "h = 0.0001#testing step size\n",
    "t0 = np.arange(0, 0.9+h, h)\n",
    "Xte = t0.reshape(1, len(t0))\n",
    "nprime = Xte.shape[1]#Number of testing samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe132291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Governing system of ODE\n",
    "\"\"\"\n",
    "\n",
    "scale = 10000# Scaling parameter for the system of ode\n",
    "\n",
    "def systemfunctions(y_hat, lamda, l):\n",
    "    f = (y_hat).copy()\n",
    "    if l>1:\n",
    "        z1 = 0\n",
    "        z2 = 0\n",
    "        for j in range(l):\n",
    "            z1 += y_hat[j]\n",
    "            z2 += y_hat[j+1]\n",
    "        f[0] = (lamda[0]*(1-z1)-lamda[1]*y_hat[0]*(1-z2))\n",
    "        for i in range(1,p-l):\n",
    "            z1 = 0\n",
    "            z2 = 0\n",
    "            for j in range(i,i+l):\n",
    "                z1 += y_hat[j]\n",
    "                z2 += y_hat[j+1]\n",
    "            f[i] = lamda[i]*y_hat[i-1]*(1-z1)-lamda[i+1]*(y_hat[i])*(1-z2)\n",
    "        z1 = 0\n",
    "        for j in range(p-l,p):\n",
    "            z1 += y_hat[j]\n",
    "        f[p-l] = lamda[p-l]*y_hat[p-l-1]*(1-z1)-lamda[p-l+1]*y_hat[p-l]\n",
    "        for i in range(p-l+1,p):\n",
    "            f[i] = lamda[i]*y_hat[i-1]-lamda[i+1]*y_hat[i]\n",
    "    else:\n",
    "        f = (y_hat).copy()\n",
    "        f[0] = lamda[0]*(1-y_hat[0])-lamda[1]*y_hat[0]*(1-y_hat[1])\n",
    "        for i in range(1,p-1):\n",
    "            f[i] = lamda[i]*y_hat[i-1]*(1-y_hat[i])-lamda[i+1]*(y_hat[i])*(1-y_hat[i+1])\n",
    "        f[p-1] = lamda[p-1]*y_hat[p-2]*(1-y_hat[p-1])-lamda[p]*y_hat[p-1]\n",
    "    return scale*f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cd46c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setting Up the Neural Network for ODE\n",
    "\"\"\"\n",
    "def init_weights_biases(initialiser, N0, N1):\n",
    "    if initialiser.upper() == 'NORMAL':\n",
    "        return [np.random.normal(0,np.sqrt(2/N1),(N1,N0)), np.random.normal(0, np.sqrt(2/N1), (N1,1))]\n",
    "    if initialiser.upper() == 'UNIFORM':\n",
    "        return [np.random.uniform(0,0.05,(N1,N0)),np.random.uniform(0,0.05,(N1,1))]\n",
    "    if initialiser.upper() == 'XAVIER':\n",
    "        return [np.random.uniform(0, 1/np.sqrt(N1), (N1,N0)), np.random.normal(0, 1/np.sqrt(N1), (N1,1))]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def add_layer(input_shape, hidden_units , activation = 'sigmoid', initialiser = 'normal'): \n",
    "    weights_biases = init_weights_biases(initialiser, input_shape, hidden_units)\n",
    "    NA.append(activation)\n",
    "    NW.append(weights_biases[0])\n",
    "    NB.append(weights_biases[1])\n",
    "    return None    \n",
    "\n",
    "\n",
    "def activation_function(x, string, alpha = 0.01):\n",
    "    if string.upper() == 'SIGMOID':\n",
    "        return (1/(1+np.exp(-x)))\n",
    "    if string.upper() == 'BPS':\n",
    "        return 2*(1/(1+np.exp(-x)))-1\n",
    "#     if string.upper() == 'BPS':\n",
    "#         return (1-np.exp(-x))/(1+np.exp(-x))\n",
    "    if string.upper() == 'SIN':\n",
    "        return np.sin(3*x)\n",
    "    if string.upper()=='COS':\n",
    "        return np.cos(3*x)\n",
    "    if string.upper() == 'CUSTOM':\n",
    "        return x+np.sin(x)**2\n",
    "    if string.upper() == 'TANH':\n",
    "        return np.tanh(x)\n",
    "    if string.upper() == 'RELU':\n",
    "        y = (x)/2+np.abs(x)/2\n",
    "        return y\n",
    "    if string.upper() == 'LEAKYRELU' or string.upper() == 'LR':\n",
    "        return (x+alpha*x+np.abs(x-alpha*x))/2\n",
    "    if string.upper() == 'LINEAR':\n",
    "        return x\n",
    "    if string.upper() == 'EXPONENTIAL' or string.upper() == 'EXP':\n",
    "        return np.exp(x)\n",
    "    if string.upper() == 'ELU':\n",
    "        x[x<0] = 0.01*(np.exp(x[x<0])-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def activation_derivative(x, string, alpha = 0.01):\n",
    "    if string.upper() == 'SIGMOID':\n",
    "        return (1/(1+np.exp(-x)))*(1-(1/(1+np.exp(-x))))\n",
    "    if string.upper() == 'BPS':\n",
    "        return 2*(1/(1+np.exp(-x)))*(1-(1/(1+np.exp(-x))))\n",
    "    if string.upper() == 'SIN':\n",
    "        return 3*np.cos(3*x)\n",
    "    if string.upper() == 'COS':\n",
    "        return -3*np.sin(3*x)\n",
    "    if string.upper() == 'TANH':\n",
    "        return (1-np.tanh(x)**2)\n",
    "    if string.upper() == \"RELU\":\n",
    "        x[x<=0] = 0\n",
    "        x[x!=0] = 1\n",
    "        return x\n",
    "    if string.upper() == 'CUSTOM':\n",
    "        y = 1+2*np.sin(x)*np.cos(x)\n",
    "        return y\n",
    "    if string.upper() == 'LEAKYRELU' or string.upper() == 'LR':\n",
    "        dx = np.ones(x.shape)\n",
    "        dx[x < 0] = alpha\n",
    "        x = dx.copy()\n",
    "        return x\n",
    "    if string.upper() == 'LINEAR':\n",
    "        x = 1\n",
    "        return x\n",
    "    if string.upper() == 'EXPONENTIAL' or string.upper() == 'EXP':\n",
    "        return np.exp(x)\n",
    "    if string.upper() == 'ELU':\n",
    "        x[x>=0] = 1\n",
    "        x[x<0] = 0.01*(np.exp(x[x<0]))\n",
    "        return x\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "\n",
    "def forward_propagation(X,NA,NW,NB):\n",
    "    A = [X]\n",
    "    Z = []\n",
    "    for i in range(len(NA)):\n",
    "        Zstar = (NW[i]@A[i]+NB[i])\n",
    "        Astar = activation_function(Zstar.astype(float), NA[i])\n",
    "        Z.append(Zstar.astype(float))\n",
    "        A.append(Astar)\n",
    "    return([Z,A])\n",
    "\n",
    "\n",
    "def rmsprop(NW, NB, dW, dB, SW, SB, epsilon, lr, beta):\n",
    "    for i in range(L):\n",
    "        SW[i] = (beta*SW[i]+(1-beta)*dW[i]**2)\n",
    "        SB[i] = (beta*SB[i]+(1-beta)*dB[i]**2)\n",
    "        NW[i] = NW[i]-lr*dW[i]/(SW[i]**0.5+epsilon)\n",
    "        NB[i] = NB[i]-lr*dB[i]/(SB[i]**0.5+epsilon)\n",
    "    return [NW, NB, SW, SB]\n",
    "\n",
    "\n",
    "def adam(i, NW, NB, dW, dB, VW, VB, SW, SB, epsilon, lr, momentum, beta):\n",
    "    VWhat = VW.copy()\n",
    "    VBhat = VB.copy()\n",
    "    SWhat = SW.copy()\n",
    "    SBhat = SB.copy()\n",
    "    for j in range(L):\n",
    "        VW[j] = momentum*VW[j]+(1-momentum)*dW[j]\n",
    "        VB[j] = momentum*VB[j]+(1-momentum)*dB[j]\n",
    "        SW[j] = beta*SW[j]+(1-beta)*(dW[j]**2)\n",
    "        SB[j] = beta*SB[j]+(1-beta)*(dB[j]**2)\n",
    "        VWhat[j] = VW[j]/(1-momentum**i)\n",
    "        VBhat[j] = VB[j]/(1-momentum**i)\n",
    "        SWhat[j] = SW[j]/(1-beta**i)\n",
    "        SBhat[j] = SB[j]/(1-beta**i)\n",
    "        NW[j] = NW[j]-lr*(VWhat[j]/np.sqrt(SWhat[j]+epsilon))\n",
    "        NB[j] = NB[j]-lr*(VBhat[j]/np.sqrt(SBhat[j]+epsilon))\n",
    "    return [NW, NB, VW, VB, SW, SB]\n",
    "   \n",
    "def backward_propagation(NA, NW, Z, A, dZ, dW, dB, y_hat, f, l):\n",
    "    Adot = (np.gradient(A[L], 0.1)[0])/scale-10**-10\n",
    "    Adotdot = (np.gradient(Adot, 0.1)[0])/scale\n",
    "    dAL = [0 for i in range(p)]\n",
    "    if l>1:#if l>1\n",
    "        z2 = 0\n",
    "        penalty = 1\n",
    "        for j in range(l):\n",
    "            z2 += y_hat[j+1]\n",
    "        df0a0 = -lamda[0]*t*np.ones_like(A[L][0])-lamda[1]*t*np.ones_like(A[L][0])*(1-z2)\n",
    "        df1a0 = lamda[1]*t*np.ones_like(A[L][0])*(1-z2)\n",
    "        dAL[0] = (A[L][0]+t*Adot[0]-f[0])*(1+t*Adotdot[0]/Adot[0]-df0a0)-(A[L][1]+t*Adot[1]-f[1])*df1a0\n",
    "\n",
    "        z2 = 0\n",
    "        for j in range(l):\n",
    "            z2 += y_hat[j+2]\n",
    "        df0a1 = -lamda[0]*t*np.ones_like(A[L][1])+lamda[1]*y_hat[0]*t*np.ones_like(A[L][1])\n",
    "        df1a1 = -lamda[1]*y_hat[0]*t*np.ones_like(A[L][1])-lamda[2]*t*np.ones_like(A[L][1])*(1-z2)\n",
    "        df2a1 = lamda[2]*t*np.ones_like(A[L][1])*(1-z2)\n",
    "        dAL[1] = -(A[L][0]+t*Adot[0]-f[0])*df0a1+(A[L][1]+t*Adot[1]-f[1])*(1+t*Adotdot[1]/Adot[1]-df1a1)-(A[L][2]+t*Adot[2]-f[2])*df2a1\n",
    "\n",
    "        for i in range(2, l):\n",
    "            index = 1\n",
    "            dfa1L = [0 for j in range(i+2)]\n",
    "            dfa1R = [0 for j in range(i+2)]\n",
    "            dfa1L[0] = -lamda[0]*t*np.ones_like(A[L][i])\n",
    "            dfa1R[0] = lamda[1]*y_hat[0]*t*np.ones_like(A[L][i])\n",
    "            for j in range(1,len(dfa1R)-2):\n",
    "                    dfa1L[j] = -dfa1R[j-1]\n",
    "                    dfa1R[j] = lamda[index+1]*y_hat[index]*t*np.ones_like(A[L][i])\n",
    "                    index += 1\n",
    "            dfa1L[len(dfa1R)-2] = -dfa1R[len(dfa1R)-3]\n",
    "            z2 = 0\n",
    "            for k in range(l):\n",
    "                z2 += y_hat[i+k+1]\n",
    "            dfa1R[len(dfa1R)-2] = -lamda[index+1]*t*np.ones_like(A[L][i])*(1-z2)\n",
    "            dfa1L[len(dfa1R)-1] = -dfa1R[len(dfa1R)-2]\n",
    "            for o in range(len(dfa1R)):\n",
    "                if o!=len(dfa1R)-2:\n",
    "                    dAL[i] += -(A[L][o]+t*Adot[o]-f[o])*(dfa1L[o]+dfa1R[o])\n",
    "                if o == len(dfa1R)-2:\n",
    "                    dAL[i] += (A[L][o]+t*Adot[o]-f[o])*(1+t*Adotdot[o]/Adot[o]-(dfa1L[o]+dfa1R[o]))\n",
    "        inc = 0\n",
    "        for i in range(l,p-l):\n",
    "            dfa4L = [0 for i in range(l+2)]\n",
    "            dfa4R = [0 for i in range(l+2)]\n",
    "            dfa4R[0] = lamda[i-l+1]*y_hat[i-l]*t\n",
    "            for k in range(1,l):\n",
    "                dfa4L[k] = -dfa4R[k-1]\n",
    "                dfa4R[k] = lamda[i-l+k+1]*y_hat[i-l+k]*t*np.ones_like(A[L][i])\n",
    "            dfa4L[l] = -dfa4R[l-1]\n",
    "            z2 = 0\n",
    "            for s in range(i,l+i):\n",
    "                z2 += y_hat[s+1] \n",
    "            dfa4R[l] = -lamda[i+1]*t*np.ones_like(A[L][i])*(1-z2)\n",
    "            dfa4L[l+1] = -dfa4R[l]\n",
    "            for r in range(l+2):\n",
    "                if r!= l:\n",
    "                    dAL[i] += -(A[L][r+inc]+t*Adot[r+inc]-f[r+inc])*(dfa4L[r]+dfa4R[r])\n",
    "                if r == l:\n",
    "                    dAL[i] += (A[L][r+inc]+t*Adot[r+inc]-f[r+inc])*(1+t*Adotdot[r+inc]/Adot[r+inc]-(dfa4L[r]+dfa4R[r]))\n",
    "            inc += 1\n",
    "        dfa7R = [0 for i in range(l+2)]\n",
    "        dfa7L = [0 for i in range(l+2)]\n",
    "        dfa7R[0] = lamda[p-2*l+1]*y_hat[p-2*l]*t*np.ones_like(A[L][p-l])\n",
    "        for j in range(1,l):\n",
    "            dfa7L[j] = -dfa7R[j-1]\n",
    "            dfa7R[j] = lamda[p-2*l+1+j]*y_hat[p-2*l+j]*t*np.ones_like(A[L][p-l])\n",
    "        dfa7L[l] = -dfa7R[l-1]\n",
    "        dfa7R[l] = -lamda[p-l+1]*t*np.ones_like(A[L][p-l]) \n",
    "        dfa7L[l+1] = -dfa7R[l]\n",
    "        for r in range(l+2):\n",
    "                if r!= l:\n",
    "                    dAL[p-l] += -(A[L][r+inc]+t*Adot[r+inc]-f[r+inc])*(dfa7L[r]+dfa7R[r])\n",
    "                if r == l:\n",
    "                    dAL[p-l] += (A[L][r+inc]+t*Adot[r+inc]-f[r+inc])*(1+t*Adotdot[r+inc]/Adot[r+inc]-(dfa7L[r]+dfa7R[r]))\n",
    "        inc += 1\n",
    "        q = 0\n",
    "        for i in range(p-l+1,p-1):\n",
    "            dfa8L = [0 for i in range(l+2-q)]\n",
    "            dfa8R = [0 for i in range(l+2-q)]\n",
    "            q += 1\n",
    "            dfa8R[0] = lamda[i-l+1]*y_hat[i-l]*t*np.ones_like(A[L][i])\n",
    "            for k in range(1,len(dfa8R)-3):\n",
    "                    dfa8L[k] = -dfa8R[k-1]\n",
    "                    dfa8R[k] = lamda[i-l+k+1]*y_hat[i-l+k]*t*np.ones_like(A[L][i])\n",
    "            dfa8L[k+1] = -dfa8R[k]\n",
    "            dfa8R[k+2] = -lamda[i+1]*t*np.ones_like(A[L][i])\n",
    "            dfa8L[k+3] = -dfa8R[k+2]\n",
    "            for r in range(len(dfa8R)-2):\n",
    "                dAL[i] += -(A[L][r+inc]+t*Adot[r+inc]-f[r+inc])*(dfa8L[r]+dfa8R[r])\n",
    "            dAL[i] = dAL[i]+(A[L][i]+t*Adot[i]-f[i])*(1+t*Adotdot[i]/Adot[i]-(dfa8L[r+1]+dfa8R[r+1]))-(A[L][i+1]+t*Adot[i+1]-f[i+1])*(dfa8L[r+2]+dfa8R[r+2])\n",
    "            inc += 1\n",
    "        df6a10 = +lamda[p-l]*y_hat[p-l-1]*t*np.ones_like(A[L][p-1])\n",
    "        df7a10 = -df6a10\n",
    "        df10a10 = -lamda[p]*t*np.ones_like(A[L][p-1])\n",
    "        dAL[p-1] = -(Adot[p-l-1]+t*Adot[p-l-1]-f[p-l-1])*df6a10-(A[L][p-l]+t*Adot[p-l]-f[p-l])*df7a10+(A[L][p-1]+t*Adot[p-1]-f[p-1])*(1+t*Adotdot[p-1]/Adot[p-1]-df10a10)\n",
    "    #     print(np.array(dAL).shape)\n",
    "    \n",
    "    else:# if l = 1\n",
    "        df0a0 = -lamda[0]*t-lamda[1]*t*(1-y_hat[1])\n",
    "        df1a0 = lamda[1]*t*(1-y_hat[1])\n",
    "        dAL[0] = (A[L][0]+t*Adot[0]-f[0])*(1+t*Adotdot[0]/Adot[0]-df0a0)-(A[L][1]+t*Adot[1]-f[1])*df1a0\n",
    "\n",
    "        for i in range(1,p-1):\n",
    "            df0a1 = lamda[i]*y_hat[i-1]*t\n",
    "            df1a1 = -df0a1-lamda[i+1]*t*(1-y_hat[i+1])\n",
    "            df2a1 = lamda[i+1]*t*(1-y_hat[i+1])\n",
    "            dAL[i] = (A[L][i-1]+t*Adot[i-1]-f[i-1])*df0a1+(A[L][i]+t*Adot[i]-f[i])*(1+t*Adotdot[i]/Adot[i]-df1a1)-(A[L][i+1]+t*Adot[i+1]-f[i+1])*df2a1\n",
    "\n",
    "        dfp1ap = lamda[p-1]*y_hat[p-2]*t\n",
    "        dfpap = -dfp1ap-lamda[p]*t\n",
    "        dAL[p-1] = -(A[L][p-2]+t*Adot[p-2]-f[p-2])*dfp1ap+(A[L][p-1]+t*Adot[p-1]-f[p-1])*(1+t*Adotdot[p-1]/Adot[p-1]-dfpap)\n",
    "    dtAL = np.array(dAL).reshape(p,n)/n\n",
    "    for i in range(L-1,-1,-1):    \n",
    "        dZ[i] = dtAL*activation_derivative(Z[i],NA[i])\n",
    "        dW[i] = (dZ[i]@A[i].T)/n\n",
    "        dB[i] = np.sum(dZ[i], axis = 1, keepdims = True)/n\n",
    "        dtAL = (NW[i].T@dZ[i])/n\n",
    "    return [dZ, dW, dB]\n",
    "\n",
    "\n",
    "\n",
    "def train_model(X, epochs, NA, NW, NB, optimiser, learning_rate = 0.001, \n",
    "                momentum = 0.9, epsilon = 10**-8, beta = 0.99):\n",
    "    [dZ, dW, dB] = [[0 for i in range(L)],[0 for i in range(L)],[0 for i in range(L)]]\n",
    "    VW = [np.zeros(NW[i].shape) for i in range(L)]\n",
    "    VB = [np.zeros(NB[i].shape) for i in range(L)]\n",
    "    SW = [np.zeros(NW[i].shape) for i in range(L)]\n",
    "    SB = [np.zeros(NB[i].shape) for i in range(L)]\n",
    "    for i in range(epochs):\n",
    "        [Z, A] = forward_propagation(X, NA, NW, NB)\n",
    "        yhat = init+t*(A[L])\n",
    "        f = systemfunctions(yhat, lamda, l)\n",
    "        [dZ, dW, dB] = backward_propagation(NA, NW, Z, A, dZ, dW, dB, yhat, f, l)\n",
    "        if optimiser.upper() == 'RMSPROP':\n",
    "            [NW, NB, SW, SB] =  rmsprop(NW, NB, dW, dB, SW, SB, epsilon, learning_rate, beta)\n",
    "        elif optimiser.upper() == 'ADAM':\n",
    "            [NW, NB, VW, VB, SW, SB] = adam(i+1, NW, NB, dW, dB, VW, VB, SW, SB, epsilon, learning_rate, momentum, beta)\n",
    "        if (i/epochs)*100 in range(100):\n",
    "            print('â–ˆ', end = '')\n",
    "#     print('\\n')\n",
    "    return [NW, NB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd296b7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training and Testing the Network\n",
    "\"\"\"\n",
    "ensemblesize = 6#Number of Medians\n",
    "L = 3# Number of Hidden Layers\n",
    "for i in range(ensemblesize):\n",
    "    plt.figure(figsize = (12,10))\n",
    "    print(i+1, end = '.')\n",
    "    init = np.random.uniform(0, 1/l, (p,1))\n",
    "    [NA, NW, NB] = [[],[],[]]\n",
    "    add_layer(input_shape = 1, hidden_units = p, activation = 'tanh', initialiser = 'normal')\n",
    "    for e in range(L-2):\n",
    "        add_layer(input_shape = p, hidden_units = p, activation = 'sigmoid', initialiser = 'xavier')\n",
    "    add_layer(input_shape = p, hidden_units = p, activation = 'bps', initialiser = 'xavier')\n",
    "    \"\"\"\n",
    "    Training the CDNN on the train set\n",
    "    \"\"\"\n",
    "    [NW, NB] = train_model(Xtr, 3000, NA, NW, NB, optimiser = 'rmsprop',\n",
    "                                     learning_rate = 10**-2, momentum = 0.9, beta = 0.999)\n",
    "    \"\"\"\n",
    "    Obtaining the solutions on the test set\n",
    "    \"\"\"\n",
    "    [Z,A] = forward_propagation(Xte, NA, NW, NB)\n",
    "    vhat = init+Xte*A[L]\n",
    "    for j in range(p):\n",
    "        plt.plot(Xte.ravel(), vhat[j])\n",
    "    plt.show()\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
